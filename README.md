# Machine Learning Press Analysis

## Intro

This repo will be used to collect my visualizations and assessments of press accounts of machine learning developments. I'll also include links to others' analyses. 

Suggestions and ideas are welcome. You can send them to: Cloudquistador@monroelab.com
Use the subject heading, 'ML Press'

## Synopsis


Everyday there are media accounts about developments in the general field of artificial intelligence (often loosely defined) and machine learning. These accounts are interpretations or distillations or sometimes, hyped versions of the research papers which are the source of their subject.

In this repo, I'll collect my attempts to visualize (or, if visualization isn't possible, assess) the contents of media accounts to determine how accurately they reflect the research source material or if they reflect the actually existing state of the art (rather than hyped or misunderstood capabilities).

Full disclosure: my position on the current state AI and ML is shaped, in large measure, by the work of two researchers who've (perhaps reluctantly) taken on the role of myth and misinformation busters regarding real vs. hyped capabilities:


## Rodney Brooks

Twitter:  https://twitter.com/rodneyabrooks

Essay on the state of artifical general intelligence (AGI): https://rodneybrooks.com/agi-has-been-delayed/


## Gary Marcus

Presentation on AGI (Why we Aren't There Yet): https://youtu.be/7dnN3P2bCJo

Twitter:  https://twitter.com/GaryMarcus


## Contents to-date

[Shakespeare/Flecther Contribution Analysis](https://github.com/drmonroe/machinelearning_press_analysis/blob/master/README.md#shakespearefletcher-textual-analysis)



[Economist Reporter Claims to Interview GPT-2](https://github.com/drmonroe/machinelearning_press_analysis/blob/master/README.md#media-outlet---the-economist-an-artificial-intelligence-predicts-the-future)


[The Gradient Article by Gary Marcus](https://thegradient.pub/an-epidemic-of-ai-misinformation/)


## Pending reading 

* MIT Technology Review: Link Between Deep Neural Networks and the Universe's Structure (as expressed via math): 

https://bit.ly/2t819Oa

* Paper cited in MIT article: Why Does Deep Learning Work So Well?

https://arxiv.org/pdf/1608.08225.pdf

* Ernest Davis Paper: The Use of Deep Learning for Symbolic Integration: A Review of (Lample and Charton, 2019)

https://arxiv.org/abs/1912.05752

* Judea Pearl: The Seven Tools of Causal Inference, with Reflections on Machine Learning

https://ftp.cs.ucla.edu/pub/stat_ser/r481-reprint.pdf


## Yoshua Bengio Reading List (Bengio CV: https://mila.quebec/en/person/bengio-yoshua/)

BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop

https://arxiv.org/abs/1810.08272v2


A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms, Bengio et al., 2019: 


https://arxiv.org/abs/1901.10912


Learning Neural Causal Models from Unknown Interventions, Ke et al., 2019: 

https://arxiv.org/abs/1910.01075


Recurrent Independent Mechanisms, Goyal et al., 2019: 

https://arxiv.org/abs/1909.10893


The Consciousness Prior, Bengio et al., 2017: 

https://arxiv.org/abs/1709.08568


(NeurIPS Presentation): From System 1 Deep Learning to System 2 Deep Learning


https://slideslive.com/38921750/from-system-1-deep-learning-to-system-2-deep-learning

#################################################################










# Shakespeare/Fletcher Textual Analysis

# Media Outlet: MIT Technology Review 
## "Machine learning has revealed exactly how much of a Shakespeare play was written by someone else"

URL: https://bit.ly/35ucQg9

## Synopsis:

Text analysis is applied to Henry VIII to identify the relative points of contribution by John Fletcher and Shakespeare (per the 19th century work of James Spedding)

Research Paper: 
"Relative contributions of Shakespeare and Fletcher in Henry VIII: An Analysis Based on Most Frequent Words and Most Frequent Rhythmic Patterns"

https://arxiv.org/abs/1911.05652

# Visualization

![Shakespeare Analysis](https://mlabshare.blob.core.windows.net/malbshare/Shakespeare-Neural-Network-Story-Flow.png)

Conclusion:  The MIT account accurately reflect the results described in te reasearch paper which are impressive but narrowly focused (i.e., an excellent and creative application of textual analysis without any excessive claims).



# Media Outlet - The Economist: "An Artificial Intelligence Predicts the Future"

URL: https://worldin.economist.com/article/17521/edition2020artificial-intelligence-predicts-future


## Synopsis:  

Economist reporter Tom Standage claims to have conducted an interview with OpenAI's GPT-2 (Generative Pre-Training) language generator. It's *implied* that the interview was a traditional question and answer, give and take and that, GPT-2, therefore, is an AGI (Artificial General Intelligence) capable of participating in a coherent, ad-hoc conversation. This is challenged on Twitter by Gary Marcus, among others.  GPT-2 is able to generate responses but is unable to do so within the context of an actual conversation (language generation isn't the same thing as language comprehension).


Medium published story about GPT-2:

https://towardsdatascience.com/openai-gpt-2-understanding-language-generation-through-visualization-8252f683b2f8

OpenAI GPT-2 Research Paper:

https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf

Gary Marcus Wired story referencing GPT-2 ("If Computers are So Smart, How Come They Can't Read")

https://www.wired.com/story/adaptation-if-computers-are-so-smart-how-come-they-cant-read/







Twitter thread:

https://twitter.com/garymarcus/status/1199146018178138112?s=11


![OpenAI_Interview_Story](https://mlabshare.blob.core.windows.net/malbshare/Economist-OpenAI-Story.png)



# Gradient Article by Gary Marcus about the Dangers of Hype in AI, "An Epidemic of AI Misinformation"

Link: https://thegradient.pub/an-epidemic-of-ai-misinformation/

AI Winter: https://en.wikipedia.org/wiki/AI_winter



## Synopsis:

AI researcher Gary Marcus write about the impact of misinformation and exaggeration of capabilties on the field of AI.  The primary argument is that, as real abilities fail to match the hype, a new AI Winter may set in (i.e., research will slow down, interest will wane from funding sources, slowing progress towards actually achievable goals).

## An excerpt:


*"The media is often tempted to report each tiny new advance in a field, be it AI or nanotechnology, as a great triumph that will soon fundamentally alter our world. Occasionally, of course, new discoveries are underreported. The transistor did not make huge waves when it was first introduced, and few people initially appreciated the full potential of the Internet. But for every transistor and Internet, there are thousands or tens of thousands of minor results that are overrreported, products and ideas that never materialized, purported advances like cold fusion that have not been replicated, and experiments that lie on blind alleys that don't ultimately reshape the world, contrary to their enthusiastic initial billing."*

[...]





